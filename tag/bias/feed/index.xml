<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>bias &#8211; Amin Hosseiny Marani, PhD Student</title>
	<atom:link href="http://localhost/amin/tag/bias/feed/" rel="self" type="application/rss+xml" />
	<link></link>
	<description>Just another WordPress site</description>
	<lastBuildDate>Thu, 23 Jun 2022 19:33:20 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0</generator>
	<item>
		<title>More than Good and Bad: Human Assessments of Machine Labeling Quality Have Multiple Dimensions</title>
		<link>/2022/06/23/more-than-good-and-bad-human-assessments-of-machine-labeling-quality-have-multiple-dimensions/</link>
		
		<dc:creator><![CDATA[aminhosseiny]]></dc:creator>
		<pubDate>Thu, 23 Jun 2022 19:32:57 +0000</pubDate>
				<category><![CDATA[Projects]]></category>
		<category><![CDATA[assessment]]></category>
		<category><![CDATA[bias]]></category>
		<category><![CDATA[human assessment]]></category>
		<category><![CDATA[human-centered AI]]></category>
		<category><![CDATA[nlp]]></category>
		<category><![CDATA[topic labeling]]></category>
		<category><![CDATA[topic modeling]]></category>
		<guid isPermaLink="false">/?p=53</guid>

					<description><![CDATA[This project develops a novel measure for human assessments of quality in machine labeling tasks. The paper tests this measure across two studies, one using an unsupervised task (generating labels for topic models) and one using a supervised task (labeling framing in political news coverage). For each label, study participants responded to several items asking [&#8230;]]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image"><img src="/wp-content/uploads/2022/06/objectionable_tech_s2.svg" alt="" class="wp-image-54"/></figure>



<p>This project  develops a novel measure for human assessments of quality in machine labeling tasks. The paper tests this measure across two studies, one using an unsupervised task (generating labels for topic models) and one using a supervised task (labeling framing in political news coverage). For each label, study participants responded to several items asking them to assess each label according to a variety of different criteria.</p>



<p><br>Exploratory factor analysis of these items reveals a two-factor latent structure in participants&#8217; assessments of label quality that is consistent across both studies. Subsequent analysis demonstrates that this multi-item, two-factor measure can reveal nuances that would be missed using either a single-item measure of perceived label quality or established calculable performance metrics. The paper concludes by suggesting future directions for the development of human-centered approaches to evaluating NLP and ML systems more broadly.</p>



<p><em>This paper will be submitted soon&#8230;</em></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Bias as a Distinct Factor in Human Ratings of Machine Labelingï¿¼</title>
		<link>/2022/06/23/bias-as-a-distinct-factor-in-human-ratings-of-machine-labeling%ef%bf%bc/</link>
		
		<dc:creator><![CDATA[aminhosseiny]]></dc:creator>
		<pubDate>Thu, 23 Jun 2022 14:06:16 +0000</pubDate>
				<category><![CDATA[Projects]]></category>
		<category><![CDATA[bias]]></category>
		<category><![CDATA[human assessment]]></category>
		<category><![CDATA[nlp]]></category>
		<category><![CDATA[topic labeling]]></category>
		<category><![CDATA[topic modeling]]></category>
		<guid isPermaLink="false">/?p=18</guid>

					<description><![CDATA[This project argue that human assessments of machine labeling can reveal bias as a distinct measure separate from other perceptions of label quality. Human subjects were asked to assess the quality of automatically generated labels for a trained topic model. Quality assessments were gathered using 15 distinct self-report questions. Exploratory factor analysis identified a distinct [&#8230;]]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full is-resized"><img loading="lazy" src="/wp-content/uploads/2022/06/image.png" alt="" class="wp-image-20" width="254" height="293" srcset="/wp-content/uploads/2022/06/image.png 468w, /wp-content/uploads/2022/06/image-260x300.png 260w" sizes="(max-width: 254px) 100vw, 254px" /></figure>



<p>This project argue that human assessments of machine labeling can reveal bias as a distinct measure separate from other perceptions of label quality. Human subjects were asked to assess the quality of automatically generated labels for a trained topic model. Quality assessments were gathered using 15 distinct self-report questions. Exploratory factor analysis identified a distinct &#8220;bias&#8221; factor. This point is likely relevant for a wide variety of machine labeling tasks.</p>



<p><a href="https://github.com/aminmarani/aminmarani.github.io/raw/master/Bias_as_a_Distinct_Factor_in_Human_Rating_of_Machine_Learning.pdf" target="_blank" rel="noreferrer noopener">Want to read more?</a> </p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
